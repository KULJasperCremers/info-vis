{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3 = pd.read_csv('../ess/ess3/ess3.csv')\n",
    "# df4 = pd.read_csv('../ess/ess4/ess4.csv')\n",
    "# df5 = pd.read_csv('../ess/ess5/ess5.csv')\n",
    "# df6 = pd.read_csv('../ess/ess6/ess6.csv')\n",
    "# df7 = pd.read_csv('../ess/ess7/ess7.csv')\n",
    "# df8 = pd.read_csv('../ess/ess8/ess8.csv')\n",
    "# df9 = pd.read_csv('../ess/ess9/ess9.csv')\n",
    "# df10 = pd.read_csv('../ess/ess10/ess10.csv')\n",
    "# df10S = pd.read_csv('../ess/ess10S/ess10S.csv')\n",
    "# # print(df.head())\n",
    "# dataframes = {'df3': df3, 'df4': df4, 'df5': df5, 'df6': df6, 'df7': df7, 'df8': df8, 'df9': df9, 'df10': df10, 'df10S': df10S}\n",
    "\n",
    "df = pd.read_csv('../ess/all/ess_all/ess_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ESS1e06_7' 'ESS2e03_6' 'ESS3e03_7' 'ESS4e04_6' 'ESS5e03_5' 'ESS6e02_6'\n",
      " 'ESS7e02_3' 'ESS8e02_3' 'ESS9e03_2' 'ESS10e03_2' 'ESS10SCe03_1']\n"
     ]
    }
   ],
   "source": [
    "print(df['name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to clean\n",
    "# columns_to_clean = ['lrscale', 'stfdem', 'stfeco', 'stfedu', 'stfgov', 'stfhlth', 'stflife', 'trstep', 'trstplt', 'trstprl', 'trstprt', 'atchctr', 'atcherp', 'happy']\n",
    "columns_to_clean = ['lrscale', 'stfdem', 'stfeco', 'stfedu', 'stfgov', 'stfhlth', 'stflife', 'trstep', 'trstplt', 'trstprl', 'trstprt', 'happy']\n",
    "\n",
    "# Define the values to remove\n",
    "values_to_remove = [77, 88, 99, '*', np.nan]\n",
    "\n",
    "# cleaned_dfs = []\n",
    "# for name, df in dataframes.items():\n",
    "#     for column in columns_to_clean:\n",
    "#         df = df[~df[column].isin(values_to_remove)]\n",
    "#     cleaned_dfs.append(df)\n",
    "#     # print(f\"{name} - {df['name']}\")\n",
    "# df = pd.concat(cleaned_dfs, ignore_index=True)\n",
    "\n",
    "for column in columns_to_clean:\n",
    "    df = df[~df[column].isin(values_to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ESS2e03_6' 'ESS3e03_7' 'ESS4e04_6' 'ESS5e03_5' 'ESS6e02_6' 'ESS7e02_3'\n",
      " 'ESS8e02_3' 'ESS9e03_2' 'ESS10e03_2' 'ESS10SCe03_1']\n"
     ]
    }
   ],
   "source": [
    "print(df['name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_leaning(value):\n",
    "    if 0 <= value <= 1:\n",
    "        return 'far-left'\n",
    "    elif 2 <= value <= 3:\n",
    "        return 'left'\n",
    "    elif value == 4:\n",
    "        return 'center-left'\n",
    "    elif value == 5:\n",
    "        return 'center'\n",
    "    elif value == 6:\n",
    "        return 'center-right'\n",
    "    elif 7 <= value <= 8:\n",
    "        return 'right'\n",
    "    elif 9 <= value <= 10:\n",
    "        return 'far-right'\n",
    "\n",
    "df['leaning'] = df['lrscale'].apply(assign_leaning)\n",
    "\n",
    "# year\n",
    "version_year_dict = {1: \"2002\", 2: \"2004\", 3: \"2006\", 4: \"2008\", 5: \"2010\", 6: \"2012\", 7: \"2014\", 8: \"2016\", 9: \"2018\", 10: \"2020\"}\n",
    "df['year'] = None\n",
    "for i, row in df.iterrows():\n",
    "    version_str = row['name'].split('ESS')[1].split('e')[0]\n",
    "    version = 10 if version_str == \"10SC\" else int(version_str)\n",
    "    year = version_year_dict.get(version)\n",
    "    df.at[i,'year'] = year\n",
    "\n",
    "# satisfaction\n",
    "satisfaction_columns = ['stfdem', 'stfeco', 'stfedu', 'stfgov', 'stfhlth', 'stflife']\n",
    "df['satisfaction'] = np.round(df[satisfaction_columns].mean(axis=1),0)\n",
    "\n",
    "# trust country\n",
    "trust_columns = ['trstplt', 'trstprl', 'trstprt']\n",
    "df['trust_country'] = np.round(df[trust_columns].mean(axis=1),0)\n",
    "\n",
    "# trust eu\n",
    "df['trust_eu'] = df['trstep']\n",
    "\n",
    "# # attachment country\n",
    "# df['attachment_country'] = df['atchctr']\n",
    "\n",
    "# # attachment eu\n",
    "# df['attachment_eu'] = df['atcherp']\n",
    "\n",
    "# new_df = df[['year','cntry','leaning','happy','satisfaction','trust_country','trust_eu','attachment_country', 'attachment_eu']]\n",
    "new_df = df[['year','cntry','leaning','happy','satisfaction','trust_country','trust_eu']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2004' '2006' '2008' '2010' '2012' '2014' '2016' '2018' '2020']\n"
     ]
    }
   ],
   "source": [
    "be_years = new_df[new_df['cntry'] == 'BE']['year'].unique()\n",
    "print(be_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.loc[new_df['cntry'] == 'GR', 'cntry'] = 'EL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../json/combined_data.json\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'election_data': {'2019': {'NVA': 16.0, 'VB': 12.0, 'PS - Belgium': 9.5, 'CDV': 8.9, 'PVDA - Belgium': 8.6, 'OVLD': 8.5, 'MR': 7.6, 'SPA': 6.7, 'Ecolo': 6.1, 'Groen': 6.0, 'CDH': 3.7, 'DeFI': 2.2, 'PP - Belgium': 1.1, 'Other parties': 3.1}, '2014': {'NVA': 20.3, 'PS - Belgium': 11.7, 'CDV': 11.6, 'OVLD': 9.8, 'MR': 9.6, 'SPA': 8.8, 'Groen': 5.3, 'CDH': 5.0, 'VB': 3.7, 'PVDA - Belgium': 3.7, 'Ecolo': 3.3, 'DeFI': 1.8, 'PP - Belgium': 1.5, 'LD': 0.4, 'Other parties': 3.5}, '2010': {'NVA': 17.4, 'PS - Belgium': 13.7, 'CDV': 10.9, 'MR': 9.3, 'SPA': 9.2, 'OVLD': 8.6, 'VB': 7.8, 'CDH': 5.5, 'Ecolo': 4.8, 'Groen': 4.4, 'LD': 3.7, 'PVDA - Belgium': 1.6, 'PP - Belgium': 1.3, 'FN - Belgium': 0.5, 'Other parties': 1.3}, '2007': {'CDV/NVA': 18.5, 'MR': 12.5, 'VB': 12.0, 'OVLD': 11.8, 'PS - Belgium': 10.9, 'SPA': 10.3, 'CDH': 6.1, 'Ecolo': 5.1, 'LD': 4.0, 'Groen': 4.0, 'FN - Belgium': 2.0, 'PVDA - Belgium': 0.8, 'Other parties': 2.0}, '2003': {'OVLD': 15.3, 'SPA': 14.9, 'CDV': 13.2, 'PS - Belgium': 13.0, 'VB': 11.7, 'MR': 11.4, 'CDH': 5.5, 'NVA': 3.1, 'Ecolo': 3.1, 'Groen': 2.5, 'FN - Belgium': 2.0, 'PVDA - Belgium': 0.3, 'Other parties': 4.0}}, 'leaning_data': {'far-left': ['PVDA - Belgium'], 'left': ['PS - Belgium', 'Ecolo', 'Groen'], 'center-left': ['SPA'], 'center': [], 'center-right': ['CDV', 'OVLD', 'MR', 'CDH', 'CDV/NVA', 'DeFI'], 'right': ['NVA', 'LD'], 'far-right': ['VB', 'FN - Belgium', 'PP - Belgium']}, 'ess_data': {}}\n"
     ]
    }
   ],
   "source": [
    "# Initialize 'ess_data' in each country\n",
    "for country in data:\n",
    "    data[country]['ess_data'] = {}\n",
    "print(data['BE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Iterate over the DataFrame\n",
    "# for index, row in new_df.iterrows():\n",
    "#     # Get country and year\n",
    "#     country = row['cntry']\n",
    "#     year = row['year']\n",
    "\n",
    "#     # Initialize year in 'ess_data' if not already present\n",
    "#     if year not in data[country]['ess_data']:\n",
    "#         data[country]['ess_data'][year] = {\n",
    "#             'leaning': Counter(),\n",
    "#             'happy': Counter(),\n",
    "#             'satisfaction': Counter(),\n",
    "#             'trust_country': Counter(),\n",
    "#             'trust_eu': Counter()\n",
    "#         }\n",
    "\n",
    "#     # Append data to 'ess_data'\n",
    "#     data[country]['ess_data'][year]['leaning'].update([row['leaning']])\n",
    "#     data[country]['ess_data'][year]['happy'].update([row['happy']])\n",
    "#     data[country]['ess_data'][year]['satisfaction'].update([row['satisfaction']])\n",
    "#     data[country]['ess_data'][year]['trust_country'].update([row['trust_country']])\n",
    "#     data[country]['ess_data'][year]['trust_eu'].update([row['trust_eu']])\n",
    "\n",
    "# Iterate over the DataFrame\n",
    "for index, row in new_df.iterrows():\n",
    "    # Get country and year\n",
    "    country = row['cntry']\n",
    "    year = row['year']\n",
    "\n",
    "    # Initialize year in 'ess_data' if not already present\n",
    "    if year not in data[country]['ess_data']:\n",
    "        data[country]['ess_data'][year] = {\n",
    "            'leaning': [],\n",
    "            'happy': [],\n",
    "            'satisfaction': [],\n",
    "            'trust_country': [],\n",
    "            'trust_eu': []\n",
    "        }\n",
    "\n",
    "    # Append data to 'ess_data'\n",
    "    data[country]['ess_data'][year]['leaning'].append(row['leaning'])\n",
    "    data[country]['ess_data'][year]['happy'].append(row['happy'])\n",
    "    data[country]['ess_data'][year]['satisfaction'].append(row['satisfaction'])\n",
    "    data[country]['ess_data'][year]['trust_country'].append(row['trust_country'])\n",
    "    data[country]['ess_data'][year]['trust_eu'].append(row['trust_eu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "# Sort 'ess_data' by year\n",
    "for country in data:\n",
    "    data[country]['ess_data'] = OrderedDict(sorted(data[country]['ess_data'].items(), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AT 2020: 1836\n",
      "AT 2018: 2026\n",
      "AT 2016: 1699\n",
      "AT 2014: 1452\n",
      "AT 2006: 1715\n",
      "AT 2004: 1685\n",
      "\n",
      "BE 2020: 1210\n",
      "BE 2018: 1619\n",
      "BE 2016: 1664\n",
      "BE 2014: 1647\n",
      "BE 2012: 1752\n",
      "BE 2010: 1576\n",
      "BE 2008: 1599\n",
      "BE 2006: 1620\n",
      "BE 2004: 1461\n",
      "\n",
      "DE 2020: 7651\n",
      "DE 2018: 2123\n",
      "DE 2016: 2607\n",
      "DE 2014: 2691\n",
      "DE 2012: 2560\n",
      "DE 2010: 2471\n",
      "DE 2008: 2246\n",
      "DE 2006: 2266\n",
      "DE 2004: 2281\n",
      "\n",
      "DK 2018: 1329\n",
      "DK 2014: 1316\n",
      "DK 2012: 1417\n",
      "DK 2010: 1327\n",
      "DK 2008: 1342\n",
      "DK 2006: 1254\n",
      "DK 2004: 1169\n",
      "\n",
      "EL 2020: 2263\n",
      "EL 2010: 1796\n",
      "EL 2008: 1608\n",
      "EL 2004: 1595\n",
      "\n",
      "ES 2020: 2079\n",
      "ES 2018: 1254\n",
      "ES 2016: 1470\n",
      "ES 2014: 1408\n",
      "ES 2012: 1560\n",
      "ES 2010: 1525\n",
      "ES 2008: 1662\n",
      "ES 2006: 1349\n",
      "ES 2004: 1152\n",
      "\n",
      "FI 2020: 1463\n",
      "FI 2018: 1600\n",
      "FI 2016: 1803\n",
      "FI 2014: 1893\n",
      "FI 2012: 2001\n",
      "FI 2010: 1695\n",
      "FI 2008: 1964\n",
      "FI 2006: 1739\n",
      "FI 2004: 1783\n",
      "\n",
      "FR 2020: 1585\n",
      "FR 2018: 1677\n",
      "FR 2016: 1835\n",
      "FR 2014: 1697\n",
      "FR 2012: 1789\n",
      "FR 2010: 1572\n",
      "FR 2008: 1843\n",
      "FR 2006: 1758\n",
      "FR 2004: 1559\n",
      "\n",
      "IE 2020: 1293\n",
      "IE 2018: 1721\n",
      "IE 2016: 1976\n",
      "IE 2014: 1694\n",
      "IE 2012: 1984\n",
      "IE 2010: 1854\n",
      "IE 2008: 1521\n",
      "IE 2006: 1275\n",
      "IE 2004: 1614\n",
      "\n",
      "IT 2020: 1824\n",
      "IT 2018: 1823\n",
      "IT 2016: 1560\n",
      "IT 2012: 708\n",
      "\n",
      "LU 2004: 1018\n",
      "\n",
      "NL 2020: 1269\n",
      "NL 2018: 1413\n",
      "NL 2016: 1404\n",
      "NL 2014: 1630\n",
      "NL 2012: 1595\n",
      "NL 2010: 1557\n",
      "NL 2008: 1505\n",
      "NL 2006: 1560\n",
      "NL 2004: 1457\n",
      "\n",
      "PT 2020: 1212\n",
      "PT 2018: 834\n",
      "PT 2016: 1053\n",
      "PT 2014: 1006\n",
      "PT 2012: 1326\n",
      "PT 2010: 1186\n",
      "PT 2008: 1272\n",
      "PT 2006: 1245\n",
      "PT 2004: 1127\n",
      "\n",
      "SE 2020: 2125\n",
      "SE 2018: 1318\n",
      "SE 2016: 1288\n",
      "SE 2014: 1441\n",
      "SE 2012: 1569\n",
      "SE 2010: 1164\n",
      "SE 2008: 1452\n",
      "SE 2006: 1307\n",
      "SE 2004: 1537\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for country in data:\n",
    "    for year in data[country]['ess_data']:\n",
    "        print(f\"{country} {year}: {len(data[country]['ess_data'][year]['happy'])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ess_data_all.json', 'w') as f:\n",
    "    json.dump(data, f, indent=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
